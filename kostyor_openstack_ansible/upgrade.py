# This file is part of OpenStack Ansible driver for Kostyor.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import os

from ansible.cli.playbook import PlaybookCLI
from ansible.executor.playbook_executor import PlaybookExecutor
from ansible.inventory import Inventory
from ansible.parsing.dataloader import DataLoader
from ansible.vars import VariableManager

from kostyor.db import api as dbapi
from kostyor.upgrades.drivers import base
from kostyor.rpc.app import app
from kostyor.rpc import tasks


def _get_component_from_service(service):
    # OpenStack services has the following naming format: '{component}-*',
    # so we can use first part before dash as a component name.
    return service['name'].split('-')[0]


def _get_component_hosts_on_node(inventory, service, host):
    component = _get_component_from_service(service)
    variables = inventory.get_vars(host['hostname'])
    hostgroup = inventory.get_group(variables['container_types'])

    # Despite the fact that 'container_types' host variable always exists,
    # it may points to non-existing group. For instance, compute hosts
    # have 'container_types=computeX-host_containers' but the group
    # doesn't exist within inventory.
    if hostgroup is not None:
        containers = hostgroup.get_hosts()
    else:
        containers = []

    # Not all services are running in containers, so we want to add the
    # host itself into the list.
    hosts = containers + inventory.get_hosts(host['hostname'])
    service_hosts = inventory.get_group(component + '_all').get_hosts()

    # Herer's the trick: intersection between node hosts and service hosts
    # (which include hosts from different nodes) gives ua only service
    # hosts on a given node.
    return list(set(hosts) & set(service_hosts))


@app.task
def _run_playbook(playbook, service, node):
    # Unfortunately, there's no good way to get the options instance
    # with proper defaults since it's generated by argparse inside
    # PlaybookCLI. Due to the fact that the options can't be empty
    # and must contain proper values we have not choice but extract
    # them from PlaybookCLI instance.
    playbook_cli = PlaybookCLI(['to-be-stripped', playbook])
    playbook_cli.parse()
    options = playbook_cli.options

    # Get others required options.
    loader = DataLoader()
    variable_manager = VariableManager()
    inventory = Inventory(loader, variable_manager)
    variable_manager.set_inventory(inventory)

    # OpenStack Ansible deploys control plane services in LXC containers,
    # and use those as native hosts in its inventory. However, from
    # Kostyor's POV we are interested in baremetal node-by-node upgrade,
    # so we need to limit playbook execution only to baremetal node under
    # upgrade and its service's containers.
    inventory.subset([
        host.get_vars()['inventory_hostname']
        for host in _get_component_hosts_on_node(inventory, service, node)
    ])

    # Finally, we can create a playbook executor and run the playbook.
    executor = PlaybookExecutor(
        playbooks=[playbook],
        inventory=inventory,
        variable_manager=variable_manager,
        loader=loader,
        options=options,
        passwords={}
    )
    executor.run()


class Driver(base.UpgradeDriver):
    """Upgrade driver implementation for OpenStack Ansible.

    As any upgrade driver returns a Celery task to be executed in order to
    achieve some goal (start upgrade, stop upgrade, etc). In order to have
    a successful execution it's mandatory to run those tasks on deployment
    host, so make sure you run your Celery worker there.

    Since OpenStack Ansible Newton we have the 'openstack-ansible.rc' shell
    script that must be sourced before running OpenStack Ansible and defines
    some Ansible env variables such as path to inventory. In order to avoid
    unnecessary complications in driver and to support as many versions as
    possible, it's up to end user to ensure that Celery worker is running
    with those env variables.

    There's another important note, hostnames in Kostyor's database must
    be the same used by OpenStack Ansible. So far we don't support
    mapping by IP address or something like that.
    """

    #: Kostyor is designed to have an upgrade resolution up to microservice.
    #: Unfortunately, OpenStack Ansible provides a resolution up to service,
    #: so technically we have the very same playbook for the whole list of
    #: service's subservices.
    _playbooks = {
        'keystone-wsgi-admin':       'os-keystone-install.yml',
        'keystone-wsgi-public':      'os-keystone-install.yml',

        'glance-api':                'os-glance-install.yml',
        'glance-registry':           'os-glance-install.yml',

        'nova-conductor':            'os-nova-install.yml',
        'nova-scheduler':            'os-nova-install.yml',
        'nova-cells':                'os-nova-install.yml',
        'nova-cert':                 'os-nova-install.yml',
        'nova-console':              'os-nova-install.yml',
        'nova-consoleauth':          'os-nova-install.yml',
        'nova-network':              'os-nova-install.yml',
        'nova-novncproxy':           'os-nova-install.yml',
        'nova-serialproxy':          'os-nova-install.yml',
        'nova-spicehtml5proxy':      'os-nova-install.yml',
        'nova-xvpvncproxy':          'os-nova-install.yml',
        'nova-api':                  'os-nova-install.yml',
        'nova-api-metadata':         'os-nova-install.yml',
        'nova-api-os-compute':       'os-nova-install.yml',
        'nova-compute':              'os-nova-install.yml',

        'neutron-server':            'os-neutron-install.yml',
        'neutron-openvswitch-agent': 'os-neutron-install.yml',
        'neutron-linuxbridge-agent': 'os-neutron-install.yml',
        'neutron-sriov-nic-agent':   'os-neutron-install.yml',
        'neutron-l3-agent':          'os-neutron-install.yml',
        'neutron-dhcp-agent':        'os-neutron-install.yml',
        'neutron-metering-agent':    'os-neutron-install.yml',
        'neutron-metadata-agent':    'os-neutron-install.yml',
        'neutron-ns-metadata-proxy': 'os-neutron-install.yml',

        'cinder-api':                'os-cinder-install.yml',
        'cinder-scheduler':          'os-cinder-install.yml',

        'heat-api':                  'os-heat-install.yml',
        'heat-engine':               'os-heat-install.yml',
        'heat-api-cfn':              'os-heat-install.yml',
        'heat-api-cloudwatch':       'os-heat-install.yml',

        'horizon-wsgi':              'os-horizon-install.yml',
    }

    # A path to OpenStack Ansible playbooks.
    #
    # TODO: to be configurable
    _playbooks_path = os.path.join('/opt', 'openstack-ansible', 'playbooks')

    def __init__(self, *args, **kwargs):
        super(Driver, self).__init__(*args, **kwargs)

        #: Due to the fact that we have one playbook that upgrades the whole
        #: service (multiple microservices at once), we will upgrade them all
        #: on the same host when firing, for instance, nova-api. In order
        #: to prevent running this playbook once again (it makes no sense),
        #: we need to track playbook executions per host.
        #:
        #: The dict has the following format:
        #:
        #:   (host, playbook) -> is-executed
        self._executions = {}

    def start_upgrade(self, upgrade_task, service):
        # Kostyor's model may contain information about more services
        # than we support. It seems reasonable to do not fail on such
        # services and skip it for now.
        if service['name'] not in self._playbooks:
            return tasks.noop.si()

        # If playbook was executed on the host, then do nothing since.
        # This is a general case for this driver as long as one playbook
        # upgrades the whole service at once.
        key = service['host_id'], self._playbooks[service['name']]
        if self._executions.get(key):
            return tasks.noop.si()
        self._executions[key] = True

        return _run_playbook.si(
            os.path.join(
                self._playbooks_path,
                self._playbooks[service['name']],
            ),
            service,
            dbapi.get_host(service['host_id']),
        )

    def stop_upgrade(self, upgrade_task, service):
        raise NotImplementedError()

    def pause_upgrade(self, upgrade_task, service):
        raise NotImplementedError()

    def continue_upgrade(self, upgrade_task, service):
        raise NotImplementedError()

    def cancel_upgrade(self, upgrade_task, service):
        raise NotImplementedError()

    def rollback_upgrade(self, upgrade_task, service):
        raise NotImplementedError()

    def supports_upgrade_rollback(self):
        return False
